{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtags_data = pandas.read_csv(\"../data_collection/hashtags_data.csv\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build feature extractor\n",
    "feature_extraction = TfidfVectorizer(min_df=0.1, sublinear_tf=True)\n",
    "feature_extraction.fit(hashtags_data[\"hashtags\"].values)\n",
    "X = feature_extraction.transform(hashtags_data[\"hashtags\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= hashtags_data[\"label\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train classifier\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC yields 0.986486486486\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate predictions\n",
    "predictions = clf.predict(X_test)\n",
    "print('ROC-AUC yields ' + str(roc_auc_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0] [0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions, y_test, [x - y for x, y in zip(predictions, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Comment after first prediction\n",
    "\n",
    "The results above are great, we managed to accuratemy predict the political view for several twitter accounts. We will now look at parameter tuning, to increase our prediction score even more.\n",
    "To do so, we will use a tool provided by Scikit learn, called GridSearchCV. Given a range of possibilities for our parameters, GridSearchCV will test every combination itself, returning the best parameters for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=0.03,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.9880952380952381\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X = vect.fit_transform(hashtags_data[\"hashtags\"].values)\n",
    "\n",
    "params = {\"svc__C\": [.01, .1, 1, 10, 100],\n",
    "          \"svc__kernel\": ['rbf', 'poly', 'linear'],\n",
    "          \"tfidf__min_df\": [.01, .03, .05, .01, .02],\n",
    "          \"tfidf__sublinear_tf\": [True, False]}\n",
    "\n",
    "clf = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                (\"svc\", SVC())])\n",
    "\n",
    "estimator = GridSearchCV(clf, params, verbose=0, n_jobs=2)\n",
    "estimator.fit(hashtags_data[\"hashtags\"].values, hashtags_data[\"label\"].values)\n",
    "\n",
    "print(estimator.best_estimator_)\n",
    "print(estimator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=0.03,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('svc', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))]\n"
     ]
    }
   ],
   "source": [
    "print(estimator.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', TfidfVectorizer(min_df=0.05, sublinear_tf=True)), ('svc', SVC(C=1, kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our algorithm's final score is: 0.988095238095\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, hashtags_data[\"hashtags\"].values, hashtags_data[\"label\"].values, cv=3)\n",
    "print ('Our algorithm\\'s final score is:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test with user mentions\n",
    "\n",
    "In our data extraction we also kept the user mentions in the tweets. Let's have a quick try at using these to predict the political view, using the same techniques as hashtags. We will mostly copy the code that was already written, since the process is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stephsmithfl danp_att arringtond3 hispaniccauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>girlscouts bradybuzz repjackyrosen averywgardi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>secretarysonny famu_1887 repallawsonjr lrobins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>repespaillat repjohnlewis mmviverito cunydream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>officialcbc ducksunlimited agriculturede shalo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           mentions\n",
       "0      0  stephsmithfl danp_att arringtond3 hispaniccauc...\n",
       "1      0  girlscouts bradybuzz repjackyrosen averywgardi...\n",
       "2      0  secretarysonny famu_1887 repallawsonjr lrobins...\n",
       "3      0  repespaillat repjohnlewis mmviverito cunydream...\n",
       "4      0  officialcbc ducksunlimited agriculturede shalo..."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_data = pandas.read_csv(\"../data_collection/mentions_data.csv\", )\n",
    "mentions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build feature extractor\n",
    "feature_extraction = TfidfVectorizer(min_df=0.1, sublinear_tf=True)\n",
    "feature_extraction.fit(mentions_data[\"mentions\"].values)\n",
    "X = feature_extraction.transform(mentions_data[\"mentions\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= mentions_data[\"label\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train classifier\n",
    "clf = Pipeline([('vect', TfidfVectorizer(min_df=0.05, sublinear_tf=True)), ('svm', SVC(C=1, kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our algorithm's final score is: 0.988147914033\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, mentions_data[\"mentions\"].values, mentions_data[\"label\"].values, cv=3)\n",
    "print ('Our algorithm\\'s final score is:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=0.02,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.9970414201183432\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X = vect.fit_transform(mentions_data[\"mentions\"].values)\n",
    "\n",
    "params = {\"svc__C\": [.01, .1, 1, 10, 100],\n",
    "          \"svc__kernel\": ['linear'],\n",
    "          \"tfidf__min_df\": [.01, .03, .05, .01, .02],\n",
    "          \"tfidf__sublinear_tf\": [True]}\n",
    "\n",
    "clf = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                (\"svc\", SVC())])\n",
    "\n",
    "estimator = GridSearchCV(clf, params, verbose=0, n_jobs=2)\n",
    "estimator.fit(mentions_data[\"mentions\"].values, mentions_data[\"label\"].values)\n",
    "\n",
    "print(estimator.best_estimator_)\n",
    "print(estimator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=0.02,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('svc', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))]\n"
     ]
    }
   ],
   "source": [
    "print(estimator.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train classifier\n",
    "clf = Pipeline([('vect', TfidfVectorizer(min_df=0.02, sublinear_tf=True)), ('svm', SVC(C=10, kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our algorithm's final score is: 0.997050147493\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, mentions_data[\"mentions\"].values, mentions_data[\"label\"].values, cv=3)\n",
    "print ('Our algorithm\\'s final score is:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test with urls\n",
    "\n",
    "In our data extraction we also kept the urls in the tweets. Let's have a quick try at using these to predict the political view, using the same techniques as hashtags. We will mostly copy the code that was already written, since the process is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.businessinsider.com/ http://www.tam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>https://lasvegassun.com/ http://www.mcclatchyd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>https://usat.ly/ https://medium.com/ https://m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>http://thehill.com/ https://www.healthcare.gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>http://thndr.me/ http://www.healthcare.gov/ ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               urls\n",
       "0      0  http://www.businessinsider.com/ http://www.tam...\n",
       "1      0  https://lasvegassun.com/ http://www.mcclatchyd...\n",
       "2      0  https://usat.ly/ https://medium.com/ https://m...\n",
       "3      0  http://thehill.com/ https://www.healthcare.gov...\n",
       "4      0  http://thndr.me/ http://www.healthcare.gov/ ht..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_data = pandas.read_csv(\"../data_collection/urls_data.csv\", )\n",
    "urls_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build feature extractor\n",
    "feature_extraction = TfidfVectorizer(min_df=0.1, sublinear_tf=True)\n",
    "feature_extraction.fit(urls_data[\"urls\"].values)\n",
    "X = feature_extraction.transform(urls_data[\"urls\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= urls_data[\"label\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train classifier\n",
    "clf = Pipeline([('vect', TfidfVectorizer(min_df=0.05, sublinear_tf=True)), ('svm', SVC(C=1, kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our algorithm's final score is: 0.961572903498\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, urls_data[\"urls\"].values, urls_data[\"label\"].values, cv=3)\n",
    "print ('Our algorithm\\'s final score is:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.9704142011834319\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X = vect.fit_transform(urls_data[\"urls\"].values)\n",
    "\n",
    "params = {\"svc__C\": [.01, .1, 1, 10, 100],\n",
    "          \"svc__kernel\": ['linear'],\n",
    "          \"tfidf__min_df\": [.01, .03, .05, .01, .02],\n",
    "          \"tfidf__sublinear_tf\": [True]}\n",
    "\n",
    "clf = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                (\"svc\", SVC())])\n",
    "\n",
    "estimator = GridSearchCV(clf, params, verbose=0, n_jobs=2)\n",
    "estimator.fit(urls_data[\"urls\"].values, urls_data[\"label\"].values)\n",
    "\n",
    "print(estimator.best_estimator_)\n",
    "print(estimator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('svc', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))]\n"
     ]
    }
   ],
   "source": [
    " print(estimator.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on republican supporter accounts\n",
    "\n",
    "I have gathered accounts from trump supporters. Let's see if our models manages to predict that these accounts are indeed republican accounts. The exercise is much harder than what we have done before, since these new accounts don't necessarily talk about politics a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First with mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mentions_test_data = pandas.read_csv(\"../data_collection/mentions_test_data.csv\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=0.02,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mentions = Pipeline([('vect', TfidfVectorizer(min_df=0.02, sublinear_tf=True)), ('svm', SVC(C=10, kernel='linear'))])\n",
    "clf_mentions.fit(mentions_data[\"mentions\"].values, mentions_data[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
      "Our algorithm accuracy on mentions for 31 accounts : 0.709677419355\n"
     ]
    }
   ],
   "source": [
    "prediction = clf_mentions.predict(mentions_test_data['mentions'].values)\n",
    "print(prediction)\n",
    "print('Our algorithm accuracy on mentions for', len(prediction), 'accounts :', sum(prediction)/len(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtags_test_data = pandas.read_csv(\"../data_collection/hashtags_test_data.csv\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=0.05,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_hashtags = Pipeline([('vect', TfidfVectorizer(min_df=0.05, sublinear_tf=True)), ('svc', SVC(C=1, kernel='linear'))])\n",
    "clf_hashtags.fit(hashtags_data[\"hashtags\"].values, hashtags_data[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "Our algorithm accuracy on mentions for 30 accounts : 0.966666666667\n"
     ]
    }
   ],
   "source": [
    "prediction = clf_hashtags.predict(hashtags_test_data['hashtags'].values)\n",
    "print(prediction)\n",
    "print('Our algorithm accuracy on mentions for', len(prediction), 'accounts :', sum(prediction)/len(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's finish with urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls_test_data = pandas.read_csv(\"../data_collection/urls_test_data.csv\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_urls = Pipeline([('vect', TfidfVectorizer(min_df=0.01, sublinear_tf=True)), ('svc', SVC(C=10, kernel='linear'))])\n",
    "clf_urls.fit(urls_data[\"urls\"].values, urls_data[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "Our algorithm accuracy on mentions for 31 accounts : 0.967741935484\n"
     ]
    }
   ],
   "source": [
    "prediction = clf_hashtags.predict(urls_test_data['urls'].values)\n",
    "print(prediction)\n",
    "print('Our algorithm accuracy on mentions for', len(prediction), 'accounts :', sum(prediction)/len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
